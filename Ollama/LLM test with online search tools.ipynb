{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e941696e",
   "metadata": {},
   "source": [
    "# LLM test with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264bfe0",
   "metadata": {},
   "source": [
    "In this file I have investigated the use of tools for the model to utilize during a run.\n",
    "\n",
    "First we import the relevant packages and connect to the model server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "import requests\n",
    "import pprint # for pretty printing\n",
    "\n",
    "client = Client(host = \"inset IP")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d87bd4",
   "metadata": {},
   "source": [
    "In the first example, I have coded a small function which can do an internet search upon request and returns the first 20000 characters on that given website.\n",
    "\n",
    "**Keep in mind** that the tools are executed on your local machine and not on the server unit (unless you run the model on your local machine). This means that all internet searches and url access happens via your local machine and the result is sent to the model afterwards.\n",
    "\n",
    "We then generate our prompt, asking the model to summarize the content of a specific website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fcd2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def internet_probe(url: str) -> str:\n",
    "    \"\"\"Fetch a URL and return its first 20000 characters.\"\"\"\n",
    "    r = requests.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    return r.text[:20000]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": (\n",
    "        \"Use the internet_probe tool to access this url:\\n\"\n",
    "        \"https://httpbin.io/html/schema\\n\"\n",
    "        \"Summarize its content. Do not focus on the coding of the website, only its actual content.\"\n",
    "    )}\n",
    "]\n",
    "\n",
    "tools = [{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"internet_probe\",\n",
    "    \"description\": \"Fetch a URL and return its first 20000 characters.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"url\": {\"type\": \"string\", \"description\": \"The URL to fetch\"}\n",
    "      },\n",
    "      \"required\": [\"url\"]\n",
    "    }\n",
    "  }\n",
    "}]\n",
    "available = {\"internet_probe\": internet_probe}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12764a",
   "metadata": {},
   "source": [
    "We can now call the model with the message that we generated and giving it access to the internet search tool. The model will look at our prompt and assess whether a tool is needed to solve the request. If a tool is needed it will return a tool request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e90aa876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'We need to use the internet_probe tool to fetch the URL.'\n",
      "---\n",
      "[ToolCall(function=Function(name='internet_probe', arguments={'url': 'https://httpbin.io/html/schema'}))]\n"
     ]
    }
   ],
   "source": [
    "# 1) call the model with the initial prompt. The model assess whether it can answer\n",
    "# directly or whether it needs to call the tool to get more information.\n",
    "# No creative thinking is allowed (temperture:0) and the context window is increased to max.\n",
    "resp = client.chat(\n",
    "    model=\"gpt-oss\", \n",
    "    messages=messages, \n",
    "    tools=tools, \n",
    "    options={\"temperature\": 0, \"num_ctx\": 131072})\n",
    "\n",
    "# 2) Extract the output of the model and check if it asked to use the tool\n",
    "messages.append(resp[\"message\"])\n",
    "tool_calls = (resp[\"message\"].get(\"tool_calls\"))\n",
    "\n",
    "# Print what the model was thinking and print whether it called for any tools\n",
    "pprint.pprint(resp[\"message\"][\"thinking\"],width=80)\n",
    "print(\"---\")\n",
    "print(tool_calls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fccbd",
   "metadata": {},
   "source": [
    "We can see that the model realized it needs to use the tool to access the given url and thus prompts for a tool use.\n",
    "\n",
    "In our case there is only a single tool to use, but in case there were more requests, we would go through all the tool calls like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63e819e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<!DOCTYPE html>\\n'\n",
      " '<html>\\n'\n",
      " '  <head>\\n'\n",
      " '  </head>\\n'\n",
      " '  <body>\\n'\n",
      " '      <h1>Herman Melville - Moby-Dick</h1>\\n'\n",
      " '\\n'\n",
      " '      <div>\\n'\n",
      " '        <p>\\n'\n",
      " '          Availing himself of the mild, summer-cool weather that now reigned '\n",
      " 'in these latitudes, and in preparation for the peculiarly active pursuits '\n",
      " 'shortly to be anticipated, Perth, the begrimed, blistered old blacksmith, '\n",
      " 'had not removed his portable forge to the hold again, after concluding his '\n",
      " \"contributory work for Ahab's leg, but still retained it on deck, fast lashed \"\n",
      " 'to ringbolts by the foremast; being now almost incessantly invoked by the '\n",
      " 'headsmen, and harpooneers, and bowsmen to do some little job for them; '\n",
      " 'altering, or repairing, or new shaping their various weapons and boat '\n",
      " 'furniture. Often he would be surrounded by an eager circle, all waiting to '\n",
      " 'be served; holding boat-spades, pike-heads, harpoons, and lances, and '\n",
      " 'jealously watching his every sooty movement, as he toiled. Nevertheless, '\n",
      " \"this old man's was a patient hammer wielded by a patient arm. No murmur, no \"\n",
      " 'impatience, no petulance did come from him. Silent, slow, and solemn; bowing '\n",
      " 'over still further his chronically broken back, he toiled away, as if toil '\n",
      " 'were life itself, and the heavy beating of his hammer the heavy beating of '\n",
      " 'his heart. And so it was.—Most miserable! A peculiar walk in this old man, a '\n",
      " 'certain slight but painful appearing yawing in his gait, had at an early '\n",
      " 'period of the voyage excited the curiosity of the mariners. And to the '\n",
      " 'importunity of their persisted questionings he had finally given in; and so '\n",
      " 'it came to pass that every one now knew the shameful story of his wretched '\n",
      " \"fate. Belated, and not innocently, one bitter winter's midnight, on the road \"\n",
      " 'running between two country towns, the blacksmith half-stupidly felt the '\n",
      " 'deadly numbness stealing over him, and sought refuge in a leaning, '\n",
      " 'dilapidated barn. The issue was, the loss of the extremities of both feet. '\n",
      " 'Out of this revelation, part by part, at last came out the four acts of the '\n",
      " 'gladness, and the one long, and as yet uncatastrophied fifth act of the '\n",
      " \"grief of his life's drama. He was an old man, who, at the age of nearly \"\n",
      " \"sixty, had postponedly encountered that thing in sorrow's technicals called \"\n",
      " 'ruin. He had been an artisan of famed excellence, and with plenty to do; '\n",
      " 'owned a house and garden; embraced a youthful, daughter-like, loving wife, '\n",
      " 'and three blithe, ruddy children; every Sunday went to a cheerful-looking '\n",
      " 'church, planted in a grove. But one night, under cover of darkness, and '\n",
      " 'further concealed in a most cunning disguisement, a desperate burglar slid '\n",
      " 'into his happy home, and robbed them all of everything. And darker yet to '\n",
      " 'tell, the blacksmith himself did ignorantly conduct this burglar into his '\n",
      " \"family's heart. It was the Bottle Conjuror! Upon the opening of that fatal \"\n",
      " 'cork, forth flew the fiend, and shrivelled up his home. Now, for prudent, '\n",
      " \"most wise, and economic reasons, the blacksmith's shop was in the basement \"\n",
      " 'of his dwelling, but with a separate entrance to it; so that always had the '\n",
      " 'young and loving healthy wife listened with no unhappy nervousness, but with '\n",
      " \"vigorous pleasure, to the stout ringing of her young-armed old husband's \"\n",
      " 'hammer; whose reverberations, muffled by passing through the floors and '\n",
      " 'walls, came up to her, not unsweetly, in her nursery; and so, to stout '\n",
      " \"Labor's iron lullaby, the blacksmith's infants were rocked to slumber. Oh, \"\n",
      " 'woe on woe! Oh, Death, why canst thou not sometimes be timely? Hadst thou '\n",
      " 'taken this old blacksmith to thyself ere his full ruin came upon him, then '\n",
      " 'had the young widow had a delicious grief, and her orphans a truly '\n",
      " 'venerable, legendary sire to dream of in their after years; and all of them '\n",
      " 'a care-killing competency.\\n'\n",
      " '        </p>\\n'\n",
      " '      </div>\\n'\n",
      " '      <script type=\"application/ld+json\">\\n'\n",
      " '          {\\n'\n",
      " '              \"@context\": \"https://schema.org\",\\n'\n",
      " '              \"@type\": \"Article\",\\n'\n",
      " '              \"name\": \"httpbin.io\",\\n'\n",
      " '              \"url\": \"https://httpbin.io/schema\",\\n'\n",
      " '              \"author\": {\\n'\n",
      " '                  \"@type\": \"Organization\",\\n'\n",
      " '                  \"name\": \"httpbin.io\"\\n'\n",
      " '              },\\n'\n",
      " '              \"publisher\": {\\n'\n",
      " '                  \"@type\": \"Organization\",\\n'\n",
      " '                  \"name\": \"httpbin.io\"\\n'\n",
      " '              },\\n'\n",
      " '              \"datePublished\": \"2023-05-24T00:00:00Z\",\\n'\n",
      " '              \"dateModified\": \"2023-05-24T00:00:00Z\",\\n'\n",
      " '              \"headline\": \"Herman Melville - Moby-Dick\"\\n'\n",
      " '          }\\n'\n",
      " '      </script>\\n'\n",
      " '  </body>\\n'\n",
      " '</html>\\n')\n"
     ]
    }
   ],
   "source": [
    "# 3) Execute tool calls as ordered by the model and generate a new message based on tool output\n",
    "for call in tool_calls:\n",
    "    fn_name = call[\"function\"][\"name\"]\n",
    "    args = call[\"function\"][\"arguments\"]\n",
    "\n",
    "    # Result from the tool\n",
    "    result = available[fn_name](**args)\n",
    "\n",
    "    # The result from the tool is appended to the original message. We use the role = tool to informe\n",
    "    #  the model that this is the output of the tool that it requested\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_name\": fn_name,\n",
    "        \"content\": result\n",
    "    })\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1b43e",
   "metadata": {},
   "source": [
    "We see that the url we accessed contains a summary of the story about Moby Dick. We not prompt the model to summarize the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5c3d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking Process: \n",
      "'We have the content. Summarize.'\n",
      "\n",
      "Final Response: \n",
      "('The page displays a short excerpt of a fictional narrative titled '\n",
      " '**“Herman\\u202fMelville –\\u202fMoby‑Dick.”**  \\n'\n",
      " 'The text is a dramatic, somewhat poetic description of an old blacksmith '\n",
      " 'named Perth who works on a ship’s deck, repairing weapons and tools for the '\n",
      " 'crew. It recounts his stoic, patient labor, his physical hardships, and a '\n",
      " 'tragic backstory involving the loss of his feet, a burglary, and a '\n",
      " 'supernatural “Bottle Conjuror” that destroys his home. The passage ends with '\n",
      " 'a lament about the timing of death and the sorrow it brings to the '\n",
      " 'blacksmith’s family.\\n'\n",
      " '\\n'\n",
      " 'Below the story, a JSON‑LD block provides structured data for the page, '\n",
      " 'identifying it as an **Article** with the name “httpbin.io,” published and '\n",
      " 'modified on 24\\u202fMay\\u202f2023, and a headline “Herman\\u202fMelville '\n",
      " '–\\u202fMoby‑Dick.” The article is attributed to the organization '\n",
      " '“httpbin.io.”')\n"
     ]
    }
   ],
   "source": [
    "resp2 = client.chat(\n",
    "    model=\"gpt-oss\", \n",
    "    messages=messages, \n",
    "    tools=tools, \n",
    "    options={\"temperature\": 0, \"num_ctx\": 131072})\n",
    "\n",
    "# 5) print the logical steps (thinking) performed by the model\n",
    "print(\"Thinking Process: \")\n",
    "pprint.pprint(resp2[\"message\"][\"thinking\"],width=70)\n",
    "print()\n",
    "\n",
    "# 6) print the content as returned from the model. \n",
    "print(\"Final Response: \")\n",
    "pprint.pprint(resp2[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31922e",
   "metadata": {},
   "source": [
    "It worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ce562",
   "metadata": {},
   "source": [
    "# Multiple tool usage and ollama tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f55a6",
   "metadata": {},
   "source": [
    "This test requires an API key, but it can be generated for free on the ollama website enabling use of the web_search and web_fetch functions available through ollama.\n",
    "\n",
    " --- BE AWARE! --- \n",
    "\n",
    "There is a limited number of web searches allowed via the ollama tools unless you subscribe :(\n",
    "\n",
    "First we load the relevant tools and packages and connect to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7249f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ollama import Client\n",
    "import json\n",
    "\n",
    "OLLAMA_API_KEY = os.environ[\"OLLAMA_API_KEY\"] = \"Your ollama API KEY"  \n",
    "# We need to set the ollama api key before we import ollama. The API key is only needed \n",
    "# when using ollama tools such as web_search and web_fetch. You need your own API key,\n",
    "# which can be generated for free once you have a user profile at ollama.com\n",
    "\n",
    "client = Client(host = \"Insert IP adress")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f07700",
   "metadata": {},
   "source": [
    "Next we define the tools that the model can use. We need to make it clear to the model what these tools are, what inputs they take, and what output they give otherwise the model might hallucinate kwargs and break the code/loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62b356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools that we expose to the model\n",
    "available_tools = {\n",
    "    \"web_search\": client.web_search,\n",
    "    \"web_fetch\": client.web_fetch,\n",
    "}\n",
    "\n",
    "# Tools schema visible to the model\n",
    "tools_for_model = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"web_search\",\n",
    "            \"description\": \"Perform a web search for a single query and return relevant results.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The search query string.\"},\n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum results to return (default 5, max 10).\",\n",
    "                        \"minimum\": 1,\n",
    "                        \"maximum\": 10,\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"web_fetch\",\n",
    "            \"description\": \"Fetch a single web page by URL and return its title, main content, and links.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"url\": {\"type\": \"string\", \"description\": \"The URL to fetch.\"}\n",
    "                },\n",
    "                \"required\": [\"url\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a608f8d",
   "metadata": {},
   "source": [
    "Now we can generate the initial prompt, which should also include some rules for the model regarding how to use the tools and their output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f574a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_RULES = (\n",
    "    \"You are a careful research assistant.\\n\"\n",
    "    \"- If you need web content, call web_search first.\\n\"\n",
    "    \"- Only call web_fetch with a URL that appeared in the web_search results.\\n\"\n",
    "    \"- Never invent or guess URLs.\\n\"\n",
    "    \"- If a fetch fails (404/timeout/etc.), call web_search again with a better query.\\n\"\n",
    "    \"- When answering, cite which pages you used (titles/domains) in plain text.\\n\"\n",
    ")\n",
    "\n",
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_RULES},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What is the newest research published by the National Research Centre \"\n",
    "            \"for the Working Environment in Denmark?\"\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ec13f",
   "metadata": {},
   "source": [
    "In order to use fewer tokens and to make the content of the website more readable to the model, we use json dumps of the ouputs. For this we define a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5cf7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_result_to_text(result) -> str:\n",
    "    \"\"\"Make tool output compact + readable.\"\"\"\n",
    "    if isinstance(result, str):\n",
    "        return result\n",
    "    try:\n",
    "        # Pydantic models / dict-like results\n",
    "        if hasattr(result, \"model_dump\"):\n",
    "            return json.dumps(result.model_dump(), ensure_ascii=False)\n",
    "        return json.dumps(result, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c48169",
   "metadata": {},
   "source": [
    "We set a maximum number of iterations for the model to use, so that it does not continue to call tools forever. We set a limit of 15, which we loop over in a for loop.\n",
    "\n",
    "We start the loop with a prompt to the model, where we expose the available tools, and specify the context window. We also disable stream and think, so that the model does not give output untill it is ready, and so that it does not provide thoughts throughout the process.\n",
    "\n",
    "We then print statements along the loops to inform us about tool calls and their content. If the model asks for a tool we call it and append the results to the original prompt, so the model can see the history of what occurred throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75f03a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls: [ToolCall(function=Function(name='web_search', arguments={'max_results': 10, 'query': 'National Research Centre for the Working Environment Denmark newest research'}))]\n",
      "Calling tool: web_search args={'max_results': 10, 'query': 'National Research Centre for the Working Environment Denmark newest research'}\n",
      "Result snippet: {\"results\": [{\"content\": \"\\n National Research Centre for the Working Environment admin 2025-08-01T08:54:14+00:00 The National Research Centre for the Working Environment (NFA) is a government researc ...\n",
      "Tool calls: [ToolCall(function=Function(name='web_search', arguments={'max_results': 10, 'query': 'National Research Centre for the Working Environment latest research 2025'}))]\n",
      "Calling tool: web_search args={'max_results': 10, 'query': 'National Research Centre for the Working Environment latest research 2025'}\n",
      "Result snippet: {\"results\": [{\"content\": \"The National Research Centre for the Working Environment (NFA)[Skip main menu]()\\n[![Go to frontpage](https://nfa.dk/media/axrdjwfx/national_research_centre_roed_blaa_cmyk_co ...\n",
      "Tool calls: [ToolCall(function=Function(name='web_search', arguments={'max_results': 10, 'query': 'NFA \"Scand J Work Environ Health\" 2025'}))]\n",
      "Calling tool: web_search args={'max_results': 10, 'query': 'NFA \"Scand J Work Environ Health\" 2025'}\n",
      "Result snippet: {\"results\": [{\"content\": \"Workplace violence: A complex challenge demanding a systemic response - PubMed\\nClipboard, Search History, and several other advanced features are temporarily unavailable.\\n[ ...\n",
      "Tool calls: [ToolCall(function=Function(name='web_fetch', arguments={'url': 'https://www.sjweh.fi/show_abstract.php?abstract_id=4249&fullText=1'}))]\n",
      "Calling tool: web_fetch args={'url': 'https://www.sjweh.fi/show_abstract.php?abstract_id=4249&fullText=1'}\n",
      "Result snippet: {\"title\": \"Scandinavian Journal of Work, Environment &amp; Health - Workplace violence: A complex challenge demanding a systemic response\", \"content\": \"Scandinavian Journal of Work, Environment &amp;  ...\n",
      "Content: **Newest research from the National Research Centre for the Working Environment (NFA)**  \n",
      "\n",
      "| Publication | Authors | Journal & Issue | Publication date | Key focus | DOI |\n",
      "|-------------|---------|-----------------|------------------|-----------|-----|\n",
      "| *Workplace violence: A complex challenge demanding a systemic response* | Sofie Jaspers, Iben Karlsen, Birgit Aust | Scandinavian Journal of Work, Environment & Health, 51(5):349‑354 | 1 September 2025 (online 19 August 2025) | A comprehensive review of the prevalence, health consequences, and systemic prevention strategies for workplace violence, with a particular emphasis on high‑risk sectors such as health care, social work, and education. | 10.5271/sjweh.4249 |\n",
      "\n",
      "**Why this is the newest NFA research**\n",
      "\n",
      "* The article is authored by researchers affiliated with the National Research Centre for the Working Environment (see affiliation line in the article: “The National Research Centre for the Working Environment, Lersø Parkallé 105, 2100 Copenhagen, Denmark”).\n",
      "* It was published in the most recent issue of the journal (51(5), September 2025), making it the latest peer‑reviewed study coming out of the NFA as of now.\n",
      "* The paper is freely available online (PDF link on the journal page) and is indexed in PubMed and other bibliographic databases.\n",
      "\n",
      "**How to access it**\n",
      "\n",
      "* Full text PDF: <https://www.sjweh.fi/download.php?abstract_id=4249&file_nro=1>\n",
      "* DOI link: <https://doi.org/10.5271/sjweh.4249>\n",
      "\n",
      "**Citation (APA)**  \n",
      "Jaspers, S., Karlsen, I., & Aust, B. (2025). Workplace violence: A complex challenge demanding a systemic response. *Scandinavian Journal of Work, Environment & Health*, 51(5), 349‑354. https://doi.org/10.5271/sjweh.4249\n",
      "\n",
      "*Source: “Scandinavian Journal of Work, Environment & Health – Workplace violence: A complex challenge demanding a systemic response” (accessed 17 Dec 2025).*\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERS = 15  # safety: prevents infinite tool-call loops (e.g., model keeps searching forever)\n",
    "\n",
    "for step in range(MAX_ITERS):\n",
    "    # 1) Ask the model what to do next given the full conversation so far (prompt).\n",
    "    #    - If it can answer directly, it returns a normal assistant message (content).\n",
    "    #    - If it needs external info, it returns tool_calls telling which tool to run + args.\n",
    "    response = client.chat(\n",
    "        model=\"gpt-oss\",\n",
    "        messages=prompt,\n",
    "        tools=tools_for_model,                 # tool schemas the model is allowed to call\n",
    "        options={\"temperature\": 0, \"num_ctx\": 131072},  # deterministic + large context\n",
    "        stream=False,                          # return one final response object\n",
    "        think=False,                           # do not request extra \"thinking\" field\n",
    "    )\n",
    "\n",
    "    # 2) If the model produced normal text, show it.\n",
    "    if getattr(response.message, \"content\", \"\"):\n",
    "        print(\"Content:\", response.message.content)\n",
    "\n",
    "    # 3) Append the assistant message (including any tool_calls) to the conversation history.\n",
    "    #    This is crucial: the next model call needs to \"remember\" what it asked for.\n",
    "    prompt.append(response.message.model_dump())\n",
    "\n",
    "    # 4) Check whether the model asked to call any tools.\n",
    "    #    If not, it means it thinks it's done and we can stop the loop.\n",
    "    tool_calls = getattr(response.message, \"tool_calls\", None)\n",
    "    if not tool_calls:\n",
    "        break\n",
    "\n",
    "    print(\"Tool calls:\", tool_calls)\n",
    "\n",
    "    # 5) Execute each tool call the model requested (some models may call multiple tools per turn).\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        args = dict(tool_call.function.arguments or {})  # arguments the model provided for the tool\n",
    "\n",
    "        print(f\"Calling tool: {tool_name} args={args}\")\n",
    "\n",
    "        # 6) Look up the actual Python function that implements this tool.\n",
    "        function_to_call = available_tools.get(tool_name)\n",
    "\n",
    "        # 7) If the model requested a tool we didn't expose, we tell it explicitly to\n",
    "        #    prevent silent failures and helps the model choose a valid tool next.\n",
    "        if not function_to_call:\n",
    "            prompt.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": f\"Tool {tool_name} not found\",\n",
    "                \"tool_name\": tool_name\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 8) Run the tool. If it errors (404, timeout, etc.), catch and report the error\n",
    "        #    back to the model so it can recover (e.g., try a different URL or search query).\n",
    "        try:\n",
    "            result = function_to_call(**args)          # execute tool locally\n",
    "            text = tool_result_to_text(result)         # normalize tool output to a string\n",
    "        except Exception as e:\n",
    "            text = (\n",
    "                f\"Tool error calling {tool_name} with args={args}: \"\n",
    "                f\"{type(e).__name__}: {e}\"\n",
    "            )\n",
    "\n",
    "        # 9) Truncate tool output so it doesn't consume all the context window.\n",
    "        text = text[:8000]\n",
    "        print(\"Result snippet:\", text[:200].replace(\"\\n\", \" \"), \"...\")\n",
    "\n",
    "        # 10) Append the tool result as a special \"tool\" message.\n",
    "        prompt.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": text,\n",
    "            \"tool_name\": tool_name\n",
    "        })\n",
    "\n",
    "# 11) If we exit the loop normally via 'break', great.\n",
    "#     If we hit the for-loop limit without breaking, we print a warning and make a final call \n",
    "#     wihtout tools to summarize what it gathered, which might be incomplete.\n",
    "else:\n",
    "    print(f\"Stopped after {MAX_ITERS} iterations (safety limit).\")\n",
    "    prompt.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Stop calling tools now. Using ONLY the tool results already in this chat, \"\n",
    "                \"write the best possible final answer for the question: What is the newest \"\n",
    "                \"research published by the National Research Centre for the Working Environment \"\n",
    "                \"in Denmark?\"\n",
    "            )\n",
    "        })\n",
    "\n",
    "    final = client.chat(\n",
    "        model=\"gpt-oss\",\n",
    "        messages=prompt,\n",
    "        tools=[],\n",
    "        options={\"temperature\": 0, \"num_ctx\": 131072},\n",
    "        stream=False,\n",
    "        think=False,\n",
    "    )\n",
    "    print(\"Final answer:\", final.message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a22a3a",
   "metadata": {},
   "source": [
    "I have printed the results from this run in the markdown cell below, to make it easier to read, but the outcome will change with every run, so it is not very consistent. Some of my previous tests have even yeilded a response dating back to 2017 as our newest research... \n",
    "\n",
    "*The model is highly inconsistent!*\n",
    "\n",
    "## Result from the model query:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f16bd",
   "metadata": {},
   "source": [
    "Content: **Newest research from the National Research Centre for the Working Environment (NFA)**  \n",
    "\n",
    "| Publication | Authors | Journal & Issue | Publication date | Key focus | DOI |\n",
    "|-------------|---------|-----------------|------------------|-----------|-----|\n",
    "| *Workplace violence: A complex challenge demanding a systemic response* | Sofie Jaspers, Iben Karlsen, Birgit Aust | Scandinavian Journal of Work, Environment & Health, 51(5):349‑354 | 1 September 2025 (online 19 August 2025) | A comprehensive review of the prevalence, health consequences, and systemic prevention strategies for workplace violence, with a particular emphasis on high‑risk sectors such as health care, social work, and education. | 10.5271/sjweh.4249 |\n",
    "\n",
    "**Why this is the newest NFA research**\n",
    "\n",
    "* The article is authored by researchers affiliated with the National Research Centre for the Working Environment (see affiliation line in the article: “The National Research Centre for the Working Environment, Lersø Parkallé 105, 2100 Copenhagen, Denmark”).\n",
    "* It was published in the most recent issue of the journal (51(5), September 2025), making it the latest peer‑reviewed study coming out of the NFA as of now.\n",
    "* The paper is freely available online (PDF link on the journal page) and is indexed in PubMed and other bibliographic databases.\n",
    "\n",
    "**How to access it**\n",
    "\n",
    "* Full text PDF: <https://www.sjweh.fi/download.php?abstract_id=4249&file_nro=1>\n",
    "* DOI link: <https://doi.org/10.5271/sjweh.4249>\n",
    "\n",
    "**Citation (APA)**  \n",
    "Jaspers, S., Karlsen, I., & Aust, B. (2025). Workplace violence: A complex challenge demanding a systemic response. *Scandinavian Journal of Work, Environment & Health*, 51(5), 349‑354. https://doi.org/10.5271/sjweh.4249\n",
    "\n",
    "*Source: “Scandinavian Journal of Work, Environment & Health – Workplace violence: A complex challenge demanding a systemic response” (accessed 17 Dec 2025).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aerosoltools-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
