{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be76b02f",
   "metadata": {},
   "source": [
    "### Installering og brug af Ollama lokalt med python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070ff0d",
   "metadata": {},
   "source": [
    "- Open windows powershell -> type \"winget install --id Ollama.Ollama\"\n",
    "- Once complete, open anaconda powershell (or restart windows powershell) and type \"ollama pull mistral\"\n",
    "- (Optional): \n",
    "    - Create new environment (still in anaconda powershell): type \"conda create -n ollama_env python\"\n",
    "    -   Once complete, type \"conda activate ollama_env\"\n",
    "- Open your editor of choice and make sure your new environment is active (if you are reading this in a jupyter notebook, make sure to switch to your ollama environment, if you have made one)\n",
    "- Try to run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f33e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c70e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d55dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's a simple Python function to check if a number is prime:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    elif n <= 3:\n",
      "        return True\n",
      "    elif n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "```\n",
      "\n",
      "This function works by first checking if the number is less than or equal to 1, in which case it's not prime. Then it checks for small factors like 2 and 3. After that, it skips every other number starting from 5 because every even number greater than 2 can be written as the sum of two primes (e.g., 6 = 3 + 3).\n",
      "\n",
      "The function then starts checking for divisors by incrementing `i` in steps of 6 since all numbers greater than 5 that are not of the form 4*k+1 or 4*k+3 have a prime factor less than or equal to √n and can be found using this pattern (e.g., 7 is the next prime after 5, 11 is the next prime after 7, and so on).\n"
     ]
    }
   ],
   "source": [
    "code_prompt = \"Write a Python function that checks if a number is prime.\"\n",
    "response = ollama.generate(model='mistral', prompt=code_prompt)\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf091be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      " The sky appears yellow, orange, or red during sunrise and sunset due to a phenomenon called Rayleigh scattering. During these times, sunlight has to pass through more of Earth's atmosphere, and the shorter wavelength blue light is scattered out in all directions while the longer wavelength red, orange, and yellow light are able to travel further towards the observer.\n",
      "\n",
      "However, if you're asking about a specific instance where the sky appears yellow (not during sunrise or sunset), it could be due to various factors like pollution, dust storms, or even certain weather conditions such as fog or haze. These particles in the air scatter sunlight and can give the sky a yellowish tint.\n"
     ]
    }
   ],
   "source": [
    "print(\"Streaming response:\")\n",
    "for chunk in ollama.generate('mistral', 'Why is the sky yellow?', stream=True):\n",
    "    print(chunk['response'], end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba181e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ahoy matey! Me ship be a fine vessel, yarr! A sturdy galleon with sails that catch the wind like a hungry shark, and timbers as strong as Old Captain Morgan's rum! Below decks, there's a treasure trove of supplies to keep me crew fed and watered. The cannon be ready for any scallywags who cross our path. And don't forget about the Jolly Roger flying high, striking fear into the hearts of them landlubbers we pass! Arr!\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "# Define a system prompt\n",
    "system_prompt = \"You speaks and sounds like a pirate with short sentences.\"\n",
    "# Chat with a system prompt\n",
    "response = chat('mistral', \n",
    "                messages=[\n",
    "                    {'role': 'system', 'content': system_prompt},\n",
    "                    {'role': 'user', 'content': 'Tell me about your boat.'}\n",
    "                ])\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8c6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  OpenAI has released Ollama, a tool that allows users to run large language models on their local machines for enhanced privacy, control, efficiency, and cost reduction by utilizing multiple open-source models via a user-friendly interface.\n"
     ]
    }
   ],
   "source": [
    "# Example: Summarize a paragraph of text\n",
    "text = \"\"\"\n",
    "OpenAI has introduced a new tool called Ollama that lets users run large language models on local machines.\n",
    "This approach emphasizes privacy and control, as data does not leave the user's environment.\n",
    "Developers can leverage various open-source models through a simple interface, improving efficiency and reducing costs.\n",
    "\"\"\"\n",
    "prompt = f\"Summarize the following text in one sentence:\\n\\\"\\\"\\\"\\n{text}\\n\\\"\\\"\\\"\"\n",
    "result = ollama.generate(model='mistral', prompt=prompt)\n",
    "print(\"Summary:\", result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171450c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sky turned a vibrant shade of purple at s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red roses adorned the table for the special d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A brilliant orange sun rose above the horizon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>She wore a bright yellow dress to stand out i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The ocean water was a deep blue, perfect for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>The artist used a palette of earthy tones to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>A brilliant stroke of blue paint added life t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>He decided to dye his hair an electric shade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>The fireworks display painted the night sky w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>She loved the way the morning sunlight filled...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment\n",
       "1     The sky turned a vibrant shade of purple at s...\n",
       "3     Red roses adorned the table for the special d...\n",
       "5        A brilliant orange sun rose above the horizon\n",
       "7     She wore a bright yellow dress to stand out i...\n",
       "9     The ocean water was a deep blue, perfect for ...\n",
       "..                                                 ...\n",
       "191   The artist used a palette of earthy tones to ...\n",
       "193   A brilliant stroke of blue paint added life t...\n",
       "195   He decided to dye his hair an electric shade ...\n",
       "197   The fireworks display painted the night sky w...\n",
       "199   She loved the way the morning sunlight filled...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ollama.generate(model='mistral', prompt='Generate a list of 100 string elements with random sentences containing the name of a color somewhere')\n",
    "sentences = pd.Series(response['response'].split('.'))\n",
    "sentences = sentences[sentences.str.len()>10].iloc[1:]\n",
    "df = sentences.to_frame(name='comment').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3efa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               comment              color\n",
      "1     The sky turned a vibrant shade of purple at s...             purple\n",
      "3     Red roses adorned the table for the special d...                red\n",
      "5        A brilliant orange sun rose above the horizon             orange\n",
      "7     She wore a bright yellow dress to stand out i...             yellow\n",
      "9     The ocean water was a deep blue, perfect for ...               blue\n",
      "..                                                 ...                ...\n",
      "191   The artist used a palette of earthy tones to ...              brown\n",
      "193   A brilliant stroke of blue paint added life t...               blue\n",
      "195   He decided to dye his hair an electric shade ...             purple\n",
      "197   The fireworks display painted the night sky w...  red, white, green\n",
      "199   She loved the way the morning sunlight filled...             golden\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     \"comment\": [\n",
    "#         \"Why is the bike pink.\",\n",
    "#         \"The color of the phone box is red.\",\n",
    "#         \"I really like green cars.\",\n",
    "#         \"Her dress was bright yellow.\",\n",
    "#         \"The wall is painted white.\"\n",
    "#     ]\n",
    "# })\n",
    "# create a new empty column for the LLM result\n",
    "df[\"color\"] = None\n",
    "# creat a standard global prompt\n",
    "SYSTEM_PROMPT = (\n",
    "    \"Extract the color mentioned in the text. \"\n",
    "    \"Reply with ONLY the color word in lowercase (e.g., blue, red). \"\n",
    "    \"If no color is mentioned, reply with 'none'.\"\n",
    ")\n",
    "\n",
    "# loop though comments and prompt the model\n",
    "for i, comment in df[\"comment\"].items():\n",
    "    # prompt = f\"{SYSTEM_PROMPT}\\n\\nText: {comment}\"\n",
    "    \n",
    "    resp = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[{'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                    {'role': 'user', 'content': comment}],\n",
    "        stream=False,\n",
    "        options={\n",
    "          # \"temperature\": 0.1, # introduce randomness\n",
    "          \"seed\": 123, # set seed to be able to replicate results\n",
    "          },\n",
    "    )\n",
    "    color = resp[\"message\"][\"content\"].strip().lower()\n",
    "    df.at[i, \"color\"] = color # insert te answer ine the new col\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
