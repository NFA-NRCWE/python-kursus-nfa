{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be76b02f",
   "metadata": {},
   "source": [
    "### Installering og brug af Ollama lokalt med python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070ff0d",
   "metadata": {},
   "source": [
    "- Open windows powershell -> type \"winget install --id Ollama.Ollama\"\n",
    "- Once complete, open anaconda powershell (or restart windows powershell) and type \"ollama pull mistral\"\n",
    "- (Optional): \n",
    "    - Create new environment (still in anaconda powershell): type \"conda create -n ollama_env python\"\n",
    "    -   Once complete, type \"conda activate ollama_env\"\n",
    "    -   Open your editor of choice and make sure your new environment is active\n",
    "- Try to run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f33e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\b061621\\appdata\\local\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c70e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d55dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's a simple Python function to check if a number is prime:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    elif n <= 3:\n",
      "        return True\n",
      "    elif n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "```\n",
      "\n",
      "This function works by first checking if the number is less than or equal to 1, in which case it's not prime. Then it checks for small factors like 2 and 3. After that, it skips every other number starting from 5 because every even number greater than 2 can be written as the sum of two primes (e.g., 6 = 3 + 3).\n",
      "\n",
      "The function then starts checking for divisors by incrementing `i` in steps of 6 since all numbers greater than 5 that are not of the form 4*k+1 or 4*k+3 have a prime factor less than or equal to âˆšn and can be found using this pattern (e.g., 7 is the next prime after 5, 11 is the next prime after 7, and so on).\n"
     ]
    }
   ],
   "source": [
    "code_prompt = \"Write a Python function that checks if a number is prime.\"\n",
    "response = ollama.generate(model='mistral', prompt=code_prompt)\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf091be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      " The sky appears yellow, orange, or red during sunrise and sunset due to a phenomenon called Rayleigh scattering. During these times, sunlight has to pass through more of Earth's atmosphere, and the shorter wavelength blue light is scattered out in all directions while the longer wavelength red, orange, and yellow light are able to travel further towards the observer.\n",
      "\n",
      "However, if you're asking about a specific instance where the sky appears yellow (not during sunrise or sunset), it could be due to various factors like pollution, dust storms, or even certain weather conditions such as fog or haze. These particles in the air scatter sunlight and can give the sky a yellowish tint.\n"
     ]
    }
   ],
   "source": [
    "print(\"Streaming response:\")\n",
    "for chunk in ollama.generate('mistral', 'Why is the sky yellow?', stream=True):\n",
    "    print(chunk['response'], end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba181e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ahoy matey! Me ship be a fine vessel, yarr! A sturdy galleon with sails that catch the wind like a hungry shark, and timbers as strong as Old Captain Morgan's rum! Below decks, there's a treasure trove of supplies to keep me crew fed and watered. The cannon be ready for any scallywags who cross our path. And don't forget about the Jolly Roger flying high, striking fear into the hearts of them landlubbers we pass! Arr!\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "# Define a system prompt\n",
    "system_prompt = \"You speaks and sounds like a pirate with short sentences.\"\n",
    "# Chat with a system prompt\n",
    "response = chat('mistral', \n",
    "                messages=[\n",
    "                    {'role': 'system', 'content': system_prompt},\n",
    "                    {'role': 'user', 'content': 'Tell me about your boat.'}\n",
    "                ])\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8c6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  OpenAI has released Ollama, a tool that allows users to run large language models on their local machines for enhanced privacy, control, efficiency, and cost reduction by utilizing multiple open-source models via a user-friendly interface.\n"
     ]
    }
   ],
   "source": [
    "# Example: Summarize a paragraph of text\n",
    "text = \"\"\"\n",
    "OpenAI has introduced a new tool called Ollama that lets users run large language models on local machines.\n",
    "This approach emphasizes privacy and control, as data does not leave the user's environment.\n",
    "Developers can leverage various open-source models through a simple interface, improving efficiency and reducing costs.\n",
    "\"\"\"\n",
    "prompt = f\"Summarize the following text in one sentence:\\n\\\"\\\"\\\"\\n{text}\\n\\\"\\\"\\\"\"\n",
    "result = ollama.generate(model='mistral', prompt=prompt)\n",
    "print(\"Summary:\", result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee827e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
